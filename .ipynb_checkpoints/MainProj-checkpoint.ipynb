{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b37c070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from bs4 import BeautifulSoup  \n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "import requests\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ae6d98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_soup_object(html_file_name):\n",
    "    page=requests.get(html_file_name)\n",
    "    soup=BeautifulSoup(page.content,'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba8db706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_list_to_file(file_name,list_name):\n",
    "    with open(file_name, 'a') as f:\n",
    "        for li in list_name:\n",
    "            f.write(\"%s\\n\" % li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0458eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scapping articles'urls from the website\n",
    "#scrapping from multiple pages with 'loas more button' javascript link\n",
    "#used stackoverflow - https://stackoverflow.com/questions/68792444/how-to-scrape-website-if-it-has-load-more-button-to-load-more-content-on-the-pag\n",
    "def israel365news_crawler(webdriver_path,max_links):\n",
    "    driver=webdriver.Chrome(executable_path=webdriver_path)\n",
    "    soup=load_soup_object('https://www.israel365news.com/israel-news/')\n",
    "\n",
    "    try:\n",
    "        driver.maximize_window() #ensures that the window occupies the entire screen.\n",
    "        driver.implicitly_wait(10) #wait for up to 10 seconds for the element to appear before throwing an exception\n",
    "        driver.get(\"https://www.israel365news.com/israel-news/\")\n",
    "\n",
    "        urls=[]\n",
    "\n",
    "        while max_links>=0:\n",
    "            if max_links%100==0: print(f'{max_links} urls until finish')\n",
    "            #articles = driver.find_elements_by_css_selector(\"h1.elementor-heading-title.elementor-size-default\")\n",
    "            #articles=driver.find_elements(\"xpath\", \"//h1[@class='elementor-heading-title elementor-size-default']\")\n",
    "            articles=soup('h1',attrs={\"class\":\"elementor-heading-title elementor-size-default\"})\n",
    "\n",
    "            for art in articles:\n",
    "                #url=art.find_element_by_tag_name(\"a\").get_attribute(\"href\")\n",
    "                #url = art.find_element(\"xpath\", \"./a\").get_attribute(\"href\")\n",
    "                #urls.append(url)\n",
    "                #print(f'url appended: {url}')\n",
    "                a=art.find('a')\n",
    "                try:\n",
    "                    if 'href' in a.attrs:\n",
    "                        url=a.get('href')\n",
    "                        urls.append(url)\n",
    "                        #print(f'url appended: {url}')\n",
    "                        max_links-=1\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            #loadmore = driver.find_element_by_css_selector(\"a.elementor-button-link.elementor-button\")\n",
    "            loadmore=driver.find_element(\"xpath\", \"//a[contains(@class, 'elementor-button-link') and contains(@class, 'elementor-button')]\")\n",
    "\n",
    "            if loadmore.is_displayed():\n",
    "                driver.execute_script(\"arguments[0].click();\", loadmore)\n",
    "                time.sleep(5)\n",
    "            else:\n",
    "                print(\"no more articles to load\")\n",
    "                break\n",
    "\n",
    "    except StaleElementReferenceException:\n",
    "        pass\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    return urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "602ad213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hadar\\AppData\\Local\\Temp\\ipykernel_6828\\2713619630.py:5: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(executable_path=webdriver_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 urls until finish\n",
      "9900 urls until finish\n",
      "9800 urls until finish\n",
      "9700 urls until finish\n",
      "9600 urls until finish\n",
      "9500 urls until finish\n",
      "9400 urls until finish\n",
      "9300 urls until finish\n",
      "9200 urls until finish\n",
      "9100 urls until finish\n",
      "9000 urls until finish\n",
      "8900 urls until finish\n",
      "8800 urls until finish\n",
      "8700 urls until finish\n",
      "8600 urls until finish\n",
      "8500 urls until finish\n",
      "8400 urls until finish\n",
      "8300 urls until finish\n",
      "8200 urls until finish\n",
      "8100 urls until finish\n",
      "8000 urls until finish\n",
      "7900 urls until finish\n",
      "7800 urls until finish\n",
      "7700 urls until finish\n",
      "7600 urls until finish\n",
      "7500 urls until finish\n",
      "7400 urls until finish\n",
      "7300 urls until finish\n",
      "7200 urls until finish\n",
      "7100 urls until finish\n",
      "7000 urls until finish\n",
      "6900 urls until finish\n",
      "6800 urls until finish\n",
      "6700 urls until finish\n",
      "6600 urls until finish\n",
      "6500 urls until finish\n",
      "6400 urls until finish\n",
      "6300 urls until finish\n",
      "6200 urls until finish\n",
      "6100 urls until finish\n",
      "6000 urls until finish\n",
      "5900 urls until finish\n",
      "5800 urls until finish\n",
      "5700 urls until finish\n",
      "5600 urls until finish\n",
      "5500 urls until finish\n",
      "5400 urls until finish\n",
      "5300 urls until finish\n",
      "5200 urls until finish\n",
      "5100 urls until finish\n",
      "5000 urls until finish\n",
      "4900 urls until finish\n",
      "4800 urls until finish\n",
      "4700 urls until finish\n",
      "4600 urls until finish\n",
      "4500 urls until finish\n",
      "4400 urls until finish\n",
      "4300 urls until finish\n",
      "4200 urls until finish\n",
      "4100 urls until finish\n",
      "4000 urls until finish\n",
      "3900 urls until finish\n",
      "3800 urls until finish\n",
      "3700 urls until finish\n",
      "3600 urls until finish\n",
      "3500 urls until finish\n",
      "3400 urls until finish\n",
      "3300 urls until finish\n",
      "3200 urls until finish\n",
      "3100 urls until finish\n",
      "3000 urls until finish\n",
      "2900 urls until finish\n",
      "2800 urls until finish\n",
      "2700 urls until finish\n",
      "2600 urls until finish\n",
      "2500 urls until finish\n",
      "2400 urls until finish\n",
      "2300 urls until finish\n",
      "2200 urls until finish\n",
      "2100 urls until finish\n",
      "2000 urls until finish\n",
      "1900 urls until finish\n",
      "1800 urls until finish\n",
      "1700 urls until finish\n",
      "1600 urls until finish\n",
      "1500 urls until finish\n",
      "1400 urls until finish\n",
      "1300 urls until finish\n",
      "1200 urls until finish\n",
      "1100 urls until finish\n",
      "1000 urls until finish\n",
      "900 urls until finish\n",
      "800 urls until finish\n",
      "700 urls until finish\n",
      "600 urls until finish\n",
      "500 urls until finish\n",
      "400 urls until finish\n",
      "300 urls until finish\n",
      "200 urls until finish\n",
      "100 urls until finish\n",
      "0 urls until finish\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'https://www.israel365news.com/israel-news/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6828\\3322314414.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mwebdriver_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr\"C:\\Users\\hadar\\Documents\\chromedriver_win32\\chromedriver.exe\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0murls_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0misrael365news_crawler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwebdriver_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mwrite_list_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"https://www.israel365news.com/israel-news/\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0murls_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6828\\1931536750.py\u001b[0m in \u001b[0;36mwrite_list_to_file\u001b[1;34m(file_name, list_name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mwrite_list_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlist_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mli\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist_name\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mli\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'https://www.israel365news.com/israel-news/'"
     ]
    }
   ],
   "source": [
    "webdriver_path=r\"C:\\Users\\hadar\\Documents\\chromedriver_win32\\chromedriver.exe\"\n",
    "urls_list=israel365news_crawler(webdriver_path,10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7fcd615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_list_to_file('israel365news_urls.txt',urls_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "96b84296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crawl through all articles from Israel365News we've collected\n",
    "def load_articles_to_df_israel365news(urls_list):\n",
    "    headline=[]\n",
    "    writers=[]\n",
    "    date=[]\n",
    "    genre=[]\n",
    "    content=[]\n",
    "    \n",
    "    for url in urls_list:\n",
    "        soup=load_soup_object(url)\n",
    "        items=soup(\"div\",attrs={\"class\":\"elementor-widget-wrap elementor-element-populated\"})\n",
    "        headline.append(items.find(\"h1\",attrs={\"class\":\"elementor-heading-title elementor-size-default\"}).get_text().strip())\n",
    "        writers.append(items.find(\"h4\",attrs={\"class\":\"elementor-author-box__name\"}).get_text().strip())\n",
    "        date.append(items.find(\"h2\",attrs={\"class\":\"elementor-heading-title elementor-size-default\"}).get_text().strip())\n",
    "        genre.append(', '.join(items.find(\"h2\",attrs={\"class\":\"elementor-heading-title elementor-size-default\"}).find_all(\"a\").get_text().strip()))\n",
    "        content.append(items.find(\"div\",attrs={\"class\":\"elementor-widget-container\"}).get_text().strip())\n",
    "\n",
    "    df=pd.DataFrame({\"headline\":headline,\"writers\":writers,\"date\":date,\"genre\":genre,\"content\":content})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "811d60d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'find'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6828\\113761987.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mload_soup_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"https://www.israel365news.com/371373/tel-aviv-anu-museum-of-the-jewish-people-buys-codex-sassoon-for-33-5-million/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mitems\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"div\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"class\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"elementor-widget-wrap elementor-element-populated\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mheadline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"h1\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"class\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"elementor-heading-title elementor-size-default\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mwriters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"h4\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"class\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"elementor-author-box__name\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"h2\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"class\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"elementor-heading-title elementor-size-default\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2287\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2288\u001b[0m         \u001b[1;34m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2289\u001b[1;33m         raise AttributeError(\n\u001b[0m\u001b[0;32m   2290\u001b[0m             \u001b[1;34m\"ResultSet object has no attribute '%s'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2291\u001b[0m         )\n",
      "\u001b[1;31mAttributeError\u001b[0m: ResultSet object has no attribute 'find'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "headline=[]\n",
    "writers=[]\n",
    "date=[]\n",
    "genre=[]\n",
    "content=[]\n",
    "\n",
    "soup=load_soup_object(r\"https://www.israel365news.com/371373/tel-aviv-anu-museum-of-the-jewish-people-buys-codex-sassoon-for-33-5-million/\")\n",
    "items=soup(\"div\",attrs={\"class\":\"elementor-widget-wrap elementor-element-populated\"})\n",
    "headline.append(items.find(\"h1\",attrs={\"class\":\"elementor-heading-title elementor-size-default\"}).get_text().strip())\n",
    "writers.append(items.find(\"h4\",attrs={\"class\":\"elementor-author-box__name\"}).get_text().strip())\n",
    "date.append(items.find(\"h2\",attrs={\"class\":\"elementor-heading-title elementor-size-default\"}).get_text().strip())\n",
    "genre.append(', '.join(items.find(\"h2\",attrs={\"class\":\"elementor-heading-title elementor-size-default\"}).find_all(\"a\").get_text().strip()))\n",
    "content.append(items.find(\"div\",attrs={\"class\":\"elementor-widget-container\"}).get_text().strip())\n",
    "\n",
    "healine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d40e354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
