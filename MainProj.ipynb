{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8343033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from bs4 import BeautifulSoup  \n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "import requests\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbf35436",
   "metadata": {},
   "outputs": [],
   "source": [
    "webdriver_path=r\"C:\\Users\\hadar\\Documents\\chromedriver_win32\\chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ae6d98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_soup_object(html_file_name):\n",
    "    page=requests.get(html_file_name)\n",
    "    soup=BeautifulSoup(page.content,'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bf98cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_soup_object_with_file_name(html_file_name):\n",
    "    page=requests.get(html_file_name)\n",
    "    soup=BeautifulSoup(page.content,'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba8db706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_list_to_file(file_name,list_name):\n",
    "    with open(file_name, 'a') as f:\n",
    "        for li in list_name:\n",
    "            f.write(\"%s\\n\" % li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ae97033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_list_from_file(file_name):\n",
    "    with open(file_name,'r') as f:\n",
    "        lines = [line.strip() for line in f.readlines()]\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0458eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scapping articles'urls from the website\n",
    "#scrapping from multiple pages with 'loas more button' javascript link\n",
    "#used stackoverflow - https://stackoverflow.com/questions/68792444/how-to-scrape-website-if-it-has-load-more-button-to-load-more-content-on-the-pag\n",
    "def israel365news_crawler(webdriver_path,max_links):\n",
    "    driver=webdriver.Chrome(executable_path=webdriver_path)\n",
    "    soup=load_soup_object('https://www.israel365news.com/israel-news/')\n",
    "\n",
    "    try:\n",
    "        driver.maximize_window() #ensures that the window occupies the entire screen.\n",
    "        driver.implicitly_wait(10) #wait for up to 10 seconds for the element to appear before throwing an exception\n",
    "        driver.get(\"https://www.israel365news.com/israel-news/\")\n",
    "\n",
    "        urls=[]\n",
    "\n",
    "        while max_links>=0:\n",
    "            if max_links%100==0: print(f'{max_links} urls until finish')\n",
    "            #articles = driver.find_elements_by_css_selector(\"h1.elementor-heading-title.elementor-size-default\")\n",
    "            #articles=driver.find_elements(\"xpath\", \"//h1[@class='elementor-heading-title elementor-size-default']\")\n",
    "            articles=soup('h1',attrs={\"class\":\"elementor-heading-title elementor-size-default\"})\n",
    "\n",
    "            for art in articles:\n",
    "                #url=art.find_element_by_tag_name(\"a\").get_attribute(\"href\")\n",
    "                #url = art.find_element(\"xpath\", \"./a\").get_attribute(\"href\")\n",
    "                #urls.append(url)\n",
    "                #print(f'url appended: {url}')\n",
    "                a=art.find('a')\n",
    "                try:\n",
    "                    if 'href' in a.attrs:\n",
    "                        url=a.get('href')\n",
    "                        urls.append(url)\n",
    "                        #print(f'url appended: {url}')\n",
    "                        max_links-=1\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            #loadmore = driver.find_element_by_css_selector(\"a.elementor-button-link.elementor-button\")\n",
    "            loadmore=driver.find_element(\"xpath\", \"//a[contains(@class, 'elementor-button-link') and contains(@class, 'elementor-button')]\")\n",
    "\n",
    "            if loadmore.is_displayed():\n",
    "                driver.execute_script(\"arguments[0].click();\", loadmore)\n",
    "                time.sleep(5)\n",
    "            else:\n",
    "                print(\"no more articles to load\")\n",
    "                break\n",
    "\n",
    "    except StaleElementReferenceException:\n",
    "        pass\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    return urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "602ad213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hadar\\AppData\\Local\\Temp\\ipykernel_6828\\2713619630.py:5: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(executable_path=webdriver_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 urls until finish\n",
      "9900 urls until finish\n",
      "9800 urls until finish\n",
      "9700 urls until finish\n",
      "9600 urls until finish\n",
      "9500 urls until finish\n",
      "9400 urls until finish\n",
      "9300 urls until finish\n",
      "9200 urls until finish\n",
      "9100 urls until finish\n",
      "9000 urls until finish\n",
      "8900 urls until finish\n",
      "8800 urls until finish\n",
      "8700 urls until finish\n",
      "8600 urls until finish\n",
      "8500 urls until finish\n",
      "8400 urls until finish\n",
      "8300 urls until finish\n",
      "8200 urls until finish\n",
      "8100 urls until finish\n",
      "8000 urls until finish\n",
      "7900 urls until finish\n",
      "7800 urls until finish\n",
      "7700 urls until finish\n",
      "7600 urls until finish\n",
      "7500 urls until finish\n",
      "7400 urls until finish\n",
      "7300 urls until finish\n",
      "7200 urls until finish\n",
      "7100 urls until finish\n",
      "7000 urls until finish\n",
      "6900 urls until finish\n",
      "6800 urls until finish\n",
      "6700 urls until finish\n",
      "6600 urls until finish\n",
      "6500 urls until finish\n",
      "6400 urls until finish\n",
      "6300 urls until finish\n",
      "6200 urls until finish\n",
      "6100 urls until finish\n",
      "6000 urls until finish\n",
      "5900 urls until finish\n",
      "5800 urls until finish\n",
      "5700 urls until finish\n",
      "5600 urls until finish\n",
      "5500 urls until finish\n",
      "5400 urls until finish\n",
      "5300 urls until finish\n",
      "5200 urls until finish\n",
      "5100 urls until finish\n",
      "5000 urls until finish\n",
      "4900 urls until finish\n",
      "4800 urls until finish\n",
      "4700 urls until finish\n",
      "4600 urls until finish\n",
      "4500 urls until finish\n",
      "4400 urls until finish\n",
      "4300 urls until finish\n",
      "4200 urls until finish\n",
      "4100 urls until finish\n",
      "4000 urls until finish\n",
      "3900 urls until finish\n",
      "3800 urls until finish\n",
      "3700 urls until finish\n",
      "3600 urls until finish\n",
      "3500 urls until finish\n",
      "3400 urls until finish\n",
      "3300 urls until finish\n",
      "3200 urls until finish\n",
      "3100 urls until finish\n",
      "3000 urls until finish\n",
      "2900 urls until finish\n",
      "2800 urls until finish\n",
      "2700 urls until finish\n",
      "2600 urls until finish\n",
      "2500 urls until finish\n",
      "2400 urls until finish\n",
      "2300 urls until finish\n",
      "2200 urls until finish\n",
      "2100 urls until finish\n",
      "2000 urls until finish\n",
      "1900 urls until finish\n",
      "1800 urls until finish\n",
      "1700 urls until finish\n",
      "1600 urls until finish\n",
      "1500 urls until finish\n",
      "1400 urls until finish\n",
      "1300 urls until finish\n",
      "1200 urls until finish\n",
      "1100 urls until finish\n",
      "1000 urls until finish\n",
      "900 urls until finish\n",
      "800 urls until finish\n",
      "700 urls until finish\n",
      "600 urls until finish\n",
      "500 urls until finish\n",
      "400 urls until finish\n",
      "300 urls until finish\n",
      "200 urls until finish\n",
      "100 urls until finish\n",
      "0 urls until finish\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'https://www.israel365news.com/israel-news/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6828\\3322314414.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mwebdriver_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr\"C:\\Users\\hadar\\Documents\\chromedriver_win32\\chromedriver.exe\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0murls_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0misrael365news_crawler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwebdriver_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mwrite_list_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"https://www.israel365news.com/israel-news/\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0murls_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6828\\1931536750.py\u001b[0m in \u001b[0;36mwrite_list_to_file\u001b[1;34m(file_name, list_name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mwrite_list_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlist_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mli\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist_name\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mli\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'https://www.israel365news.com/israel-news/'"
     ]
    }
   ],
   "source": [
    "webdriver_path=r\"C:\\Users\\hadar\\Documents\\chromedriver_win32\\chromedriver.exe\"\n",
    "urls_list=israel365news_crawler(webdriver_path,10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7fcd615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_list_to_file('israel365news_urls.txt',urls_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "96b84296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crawl through all articles from Israel365News we've collected\n",
    "def load_articles_to_df_israel365news(urls_list):\n",
    "    headline=[]\n",
    "    writers=[]\n",
    "    date=[]\n",
    "    genre=[]\n",
    "    content=[]\n",
    "    i=0\n",
    "    \n",
    "    for url in urls_list:\n",
    "        soup=load_soup_object(url)\n",
    "        headline.append(soup.find(\"h1\",attrs={\"class\":\"elementor-heading-title elementor-size-default\"}).get_text().strip())\n",
    "        writers.append(soup.find(\"h4\",attrs={\"class\":\"elementor-author-box__name\"}).get_text().strip())\n",
    "        date.append(soup.find(\"div\",attrs={\"class\":\"elementor-element elementor-element-8f04d6d elementor-widget__width-auto elementor-widget elementor-widget-heading\"}).find(\"h2\").get_text().strip())\n",
    "        genre.append(\", \".join(item.get_text().strip() for item in soup.find(\"div\",attrs={\"class\":\"elementor-element elementor-element-1a40dbf elementor-widget__width-auto text-hover elementor-widget elementor-widget-heading\"}).find_all(\"a\")))\n",
    "        content.append(soup.find(\"div\",attrs={\"class\":\"elementor-element elementor-element-2106a85 elementor-widget elementor-widget-theme-post-content\"}).get_text().strip()) \n",
    "        i+=1\n",
    "        if(i%100==0):\n",
    "            print(f'{i} articles scrapped')\n",
    "\n",
    "    df=pd.DataFrame({\"headline\":headline,\"writers\":writers,\"date\":date,\"genre\":genre,\"content\":content})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "811d60d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 articles scrapped\n",
      "200 articles scrapped\n",
      "300 articles scrapped\n",
      "400 articles scrapped\n",
      "500 articles scrapped\n",
      "600 articles scrapped\n",
      "700 articles scrapped\n",
      "800 articles scrapped\n",
      "900 articles scrapped\n",
      "1000 articles scrapped\n",
      "1100 articles scrapped\n",
      "1200 articles scrapped\n",
      "1300 articles scrapped\n",
      "1400 articles scrapped\n",
      "1500 articles scrapped\n",
      "1600 articles scrapped\n",
      "1700 articles scrapped\n",
      "1800 articles scrapped\n",
      "1900 articles scrapped\n",
      "2000 articles scrapped\n",
      "2100 articles scrapped\n",
      "2200 articles scrapped\n",
      "2300 articles scrapped\n",
      "2400 articles scrapped\n",
      "2500 articles scrapped\n",
      "2600 articles scrapped\n",
      "2700 articles scrapped\n",
      "2800 articles scrapped\n",
      "2900 articles scrapped\n",
      "3000 articles scrapped\n",
      "3100 articles scrapped\n",
      "3200 articles scrapped\n",
      "3300 articles scrapped\n",
      "3400 articles scrapped\n",
      "3500 articles scrapped\n",
      "3600 articles scrapped\n",
      "3700 articles scrapped\n",
      "3800 articles scrapped\n",
      "3900 articles scrapped\n",
      "4000 articles scrapped\n",
      "4100 articles scrapped\n",
      "4200 articles scrapped\n",
      "4300 articles scrapped\n",
      "4400 articles scrapped\n",
      "4500 articles scrapped\n",
      "4600 articles scrapped\n",
      "4700 articles scrapped\n",
      "4800 articles scrapped\n",
      "4900 articles scrapped\n",
      "5000 articles scrapped\n",
      "5100 articles scrapped\n",
      "5200 articles scrapped\n",
      "5300 articles scrapped\n",
      "5400 articles scrapped\n",
      "5500 articles scrapped\n",
      "5600 articles scrapped\n",
      "5700 articles scrapped\n",
      "5800 articles scrapped\n",
      "5900 articles scrapped\n",
      "6000 articles scrapped\n",
      "6100 articles scrapped\n",
      "6200 articles scrapped\n",
      "6300 articles scrapped\n",
      "6400 articles scrapped\n",
      "6500 articles scrapped\n",
      "6600 articles scrapped\n",
      "6700 articles scrapped\n",
      "6800 articles scrapped\n",
      "6900 articles scrapped\n",
      "7000 articles scrapped\n",
      "7100 articles scrapped\n",
      "7200 articles scrapped\n",
      "7300 articles scrapped\n",
      "7400 articles scrapped\n",
      "7500 articles scrapped\n",
      "7600 articles scrapped\n",
      "7700 articles scrapped\n",
      "7800 articles scrapped\n",
      "7900 articles scrapped\n",
      "8000 articles scrapped\n",
      "8100 articles scrapped\n",
      "8200 articles scrapped\n",
      "8300 articles scrapped\n",
      "8400 articles scrapped\n",
      "8500 articles scrapped\n",
      "8600 articles scrapped\n",
      "8700 articles scrapped\n",
      "8800 articles scrapped\n",
      "8900 articles scrapped\n",
      "9000 articles scrapped\n",
      "9100 articles scrapped\n",
      "9200 articles scrapped\n",
      "9300 articles scrapped\n",
      "9400 articles scrapped\n",
      "9500 articles scrapped\n",
      "9600 articles scrapped\n",
      "9700 articles scrapped\n",
      "9800 articles scrapped\n",
      "9900 articles scrapped\n",
      "10000 articles scrapped\n"
     ]
    }
   ],
   "source": [
    "df=load_articles_to_df_israel365news(urls_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8d40e354",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('israel365news.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bd9de4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>writers</th>\n",
       "      <th>date</th>\n",
       "      <th>genre</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Knesset passes 2023-2024 state budget</td>\n",
       "      <td>JNS</td>\n",
       "      <td>May 24, 2023</td>\n",
       "      <td>Israel News</td>\n",
       "      <td>Israel’s Knesset on Wednesday passed the state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Will flights from Israel to Mecca spark Temple...</td>\n",
       "      <td>Adam Eliyahu Berkowitz</td>\n",
       "      <td>May 23, 2023</td>\n",
       "      <td>Israel News</td>\n",
       "      <td>Prime Minister Netanyahu was in direct contact...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rabbi Leo Dee weighs $1.3b. suit against Amanpour</td>\n",
       "      <td>JNS</td>\n",
       "      <td>May 23, 2023</td>\n",
       "      <td>Israel News</td>\n",
       "      <td>Rabbi Leo Dee is considering suing CNN chief i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Israeli Cabinet boosts funds for Kotel infrast...</td>\n",
       "      <td>JNS</td>\n",
       "      <td>May 22, 2023</td>\n",
       "      <td>Israel News</td>\n",
       "      <td>The Israeli Cabinet on Sunday approved funding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ben-Gvir visits Temple Mount: ‘We are the owne...</td>\n",
       "      <td>JNS</td>\n",
       "      <td>May 21, 2023</td>\n",
       "      <td>Israel News</td>\n",
       "      <td>During a visit to the Temple Mount in Jerusale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10015</th>\n",
       "      <td>Israeli forces kill two terrorists in raid nea...</td>\n",
       "      <td>JNS</td>\n",
       "      <td>May 10, 2023</td>\n",
       "      <td>Israel News, Judea and Samaria</td>\n",
       "      <td>Israeli forces killed two Palestinian terroris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016</th>\n",
       "      <td>IDF eliminates three top Palestinian Islamic J...</td>\n",
       "      <td>JNS</td>\n",
       "      <td>May 9, 2023</td>\n",
       "      <td>Israel News, Terror Watch</td>\n",
       "      <td>The Israel Defense Forces killed three top Pal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10017</th>\n",
       "      <td>After six years, Israel razes illegal PA struc...</td>\n",
       "      <td>JNS</td>\n",
       "      <td>May 8, 2023</td>\n",
       "      <td>Israel News</td>\n",
       "      <td>Israel’s Civil Administration demolished a Pal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10018</th>\n",
       "      <td>Jerusalem Day: Mass return to the Temple Mount...</td>\n",
       "      <td>Adam Eliyahu Berkowitz</td>\n",
       "      <td>May 7, 2023</td>\n",
       "      <td>Israel News</td>\n",
       "      <td>Temple Mount advocacy groups are planning some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10019</th>\n",
       "      <td>Netanyahu: Israel’s counterterror ops an ‘inte...</td>\n",
       "      <td>JNS</td>\n",
       "      <td>May 7, 2023</td>\n",
       "      <td>Israel News</td>\n",
       "      <td>Israeli Prime Minister Benjamin Netanyahu on S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10020 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                headline  \\\n",
       "0                  Knesset passes 2023-2024 state budget   \n",
       "1      Will flights from Israel to Mecca spark Temple...   \n",
       "2      Rabbi Leo Dee weighs $1.3b. suit against Amanpour   \n",
       "3      Israeli Cabinet boosts funds for Kotel infrast...   \n",
       "4      Ben-Gvir visits Temple Mount: ‘We are the owne...   \n",
       "...                                                  ...   \n",
       "10015  Israeli forces kill two terrorists in raid nea...   \n",
       "10016  IDF eliminates three top Palestinian Islamic J...   \n",
       "10017  After six years, Israel razes illegal PA struc...   \n",
       "10018  Jerusalem Day: Mass return to the Temple Mount...   \n",
       "10019  Netanyahu: Israel’s counterterror ops an ‘inte...   \n",
       "\n",
       "                      writers          date                           genre  \\\n",
       "0                         JNS  May 24, 2023                     Israel News   \n",
       "1      Adam Eliyahu Berkowitz  May 23, 2023                     Israel News   \n",
       "2                         JNS  May 23, 2023                     Israel News   \n",
       "3                         JNS  May 22, 2023                     Israel News   \n",
       "4                         JNS  May 21, 2023                     Israel News   \n",
       "...                       ...           ...                             ...   \n",
       "10015                     JNS  May 10, 2023  Israel News, Judea and Samaria   \n",
       "10016                     JNS   May 9, 2023       Israel News, Terror Watch   \n",
       "10017                     JNS   May 8, 2023                     Israel News   \n",
       "10018  Adam Eliyahu Berkowitz   May 7, 2023                     Israel News   \n",
       "10019                     JNS   May 7, 2023                     Israel News   \n",
       "\n",
       "                                                 content  \n",
       "0      Israel’s Knesset on Wednesday passed the state...  \n",
       "1      Prime Minister Netanyahu was in direct contact...  \n",
       "2      Rabbi Leo Dee is considering suing CNN chief i...  \n",
       "3      The Israeli Cabinet on Sunday approved funding...  \n",
       "4      During a visit to the Temple Mount in Jerusale...  \n",
       "...                                                  ...  \n",
       "10015  Israeli forces killed two Palestinian terroris...  \n",
       "10016  The Israel Defense Forces killed three top Pal...  \n",
       "10017  Israel’s Civil Administration demolished a Pal...  \n",
       "10018  Temple Mount advocacy groups are planning some...  \n",
       "10019  Israeli Prime Minister Benjamin Netanyahu on S...  \n",
       "\n",
       "[10020 rows x 5 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e674cbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making crawler for Middle East Monitor website\n",
    "def load_articles_url_MEM(n_pages):\n",
    "    soup=load_soup_object(r'https://www.middleeastmonitor.com/category/news/middle-east/')\n",
    "    articles=soup(\"li\")\n",
    "    urls=[]\n",
    "    \n",
    "    for page in range(n_pages):\n",
    "        for art in articles:\n",
    "            a=art.find('a')\n",
    "            try:\n",
    "                if 'href' in a.attrs:\n",
    "                    url=a.get('href')\n",
    "                    urls.append(url)\n",
    "            except:\n",
    "                continue\n",
    "        next_page=soup.find(\"a\",attrs={\"class\":\"next page-numbers\"})[\"href\"]\n",
    "        soup=load_soup_object(next_page)\n",
    "        articles=soup(\"li\")\n",
    "        if(page%50==0): \n",
    "            print(f'{page} pages out of 350')\n",
    "        \n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "21df0725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 pages out of 350\n",
      "50 pages out of 350\n",
      "100 pages out of 350\n",
      "150 pages out of 350\n",
      "200 pages out of 350\n",
      "250 pages out of 350\n",
      "300 pages out of 350\n"
     ]
    }
   ],
   "source": [
    "mem_urls_list=load_articles_url_MEM(350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2668f4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing links to other sites from list\n",
    "for url in mem_urls_list:\n",
    "    if(url.startswith(\"https://www.middleeastmonitor.com\")==False or len(url)<100 or url.find(\"category\")!=-1 or url.find(\"6-author\")!=-1):\n",
    "        mem_urls_list.remove(url)\n",
    "write_list_to_file('mem_urls.txt',mem_urls_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f07ca18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_urls_list=read_list_from_file('mem_urls.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aab7a404",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crawl through all articles from Israel365News we've collected\n",
    "def load_articles_to_df_mem(urls_list,start_index,max_urls):\n",
    "    headline=[]\n",
    "    writers=[]#there is no authors declared inside the articles, will be filled with Unknown\n",
    "    date=[]\n",
    "    genre=[]\n",
    "    content=[]\n",
    "    for i in range(max_urls):\n",
    "        try:\n",
    "            soup=load_soup_object(urls_list[i+start_index])\n",
    "            he=soup.find(\"div\",attrs={\"id\":\"post-page-title\"}).get_text().strip()\n",
    "            da=soup.find(\"span\",attrs={\"class\":\"post-page-date\"}).get_text().strip()\n",
    "            ge=\"+\".join(item.get_text().strip() for item in soup.find(\"div\",attrs={\"class\":\"post-meta-top\"}).find_all(\"a\"))\n",
    "            co=\" \".join(item.get_text().strip() for item in soup.find(\"div\",attrs={\"id\":\"post-content\"}).find_all(\"p\"))\n",
    "            if he and da and ge and co:\n",
    "                headline.append(he)\n",
    "                writers.append(\"Unknown\")\n",
    "                date.append(da)\n",
    "                genre.append(ge)\n",
    "                content.append(co)\n",
    "            if i%100==0:\n",
    "                print(f'{i} articles scrapped')\n",
    "            if not (len(headline)==len(writers)==len(date)==len(genre)==len(content)):\n",
    "                print(f\"problam with url {urls_list[i+start_index]}\")\n",
    "                break\n",
    "        except:\n",
    "            continue\n",
    "    print(f'headlines = {len(headline)}, writers={len(writers)}, date = {len(date)}, genre = {len(genre)}, content={len(content)}')\n",
    "    df=pd.DataFrame({\"headline\":headline,\"writers\":writers,\"date\":date,\"genre\":genre,\"content\":content})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dcdd1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 articles scrapped\n",
      "100 articles scrapped\n",
      "200 articles scrapped\n",
      "headlines = 300, writers=300, date = 300, genre = 300, content=300\n"
     ]
    }
   ],
   "source": [
    "df_mem=load_articles_to_df_mem(mem_urls_list,0,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43e15cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>writers</th>\n",
       "      <th>date</th>\n",
       "      <th>genre</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reporters Without Borders calls for Egypt to r...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>May 27, 2023 at 10:37 am</td>\n",
       "      <td>Africa+Egypt+International Organisations+News+...</td>\n",
       "      <td>Reporters Without Borders has called on the Eg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Russia, Somalia mull establishment of platform...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>May 26, 2023 at 8:11 pm</td>\n",
       "      <td>Africa+Europe &amp; Russia+News+Russia+Somalia</td>\n",
       "      <td>Somali Foreign Minister, Abshir Omar Jama, sai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turkiye homes in northern Syria for voluntary ...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>May 26, 2023 at 8:07 pm</td>\n",
       "      <td>Europe &amp; Russia+Middle East+News+Syria+Turkey</td>\n",
       "      <td>Ankara is currently working on the safe return...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lebanon to take steps to fix finance sector sh...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>May 26, 2023 at 7:59 pm</td>\n",
       "      <td>Africa+Lebanon+Middle East+News</td>\n",
       "      <td>Lebanon will work over the next year to addres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3 dead, 12 missing as migrant boat capsizes in...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>May 26, 2023 at 6:18 pm</td>\n",
       "      <td>Europe &amp; Russia+Greece+News</td>\n",
       "      <td>Three migrants were killed and twelve others a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Lebanon to take steps to fix finance sector sh...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>May 26, 2023 at 7:59 pm</td>\n",
       "      <td>Africa+Lebanon+Middle East+News</td>\n",
       "      <td>Lebanon will work over the next year to addres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>3 dead, 12 missing as migrant boat capsizes in...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>May 26, 2023 at 6:18 pm</td>\n",
       "      <td>Europe &amp; Russia+Greece+News</td>\n",
       "      <td>Three migrants were killed and twelve others a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Bahrain schools ordered by King to remove less...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>May 12, 2023 at 2:59 pm</td>\n",
       "      <td>Asia &amp; Americas+Bahrain+Israel+Middle East+New...</td>\n",
       "      <td>Bahrain's educational institutions have been o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>China resumes construction of military base in...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>April 30, 2023 at 9:33 am</td>\n",
       "      <td>Asia &amp; Americas+China+Middle East+News+UAE+US</td>\n",
       "      <td>China has resumed construction work on a milit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Brazil´s president: The UN was so strong enoug...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>April 28, 2023 at 11:43 am</td>\n",
       "      <td>Africa+Asia &amp; Americas+Brazil+Egypt+Europe &amp; R...</td>\n",
       "      <td>Brazil's President Luiz Inácio Lula da Silva t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              headline  writers  \\\n",
       "0    Reporters Without Borders calls for Egypt to r...  Unknown   \n",
       "1    Russia, Somalia mull establishment of platform...  Unknown   \n",
       "2    Turkiye homes in northern Syria for voluntary ...  Unknown   \n",
       "3    Lebanon to take steps to fix finance sector sh...  Unknown   \n",
       "4    3 dead, 12 missing as migrant boat capsizes in...  Unknown   \n",
       "..                                                 ...      ...   \n",
       "295  Lebanon to take steps to fix finance sector sh...  Unknown   \n",
       "296  3 dead, 12 missing as migrant boat capsizes in...  Unknown   \n",
       "297  Bahrain schools ordered by King to remove less...  Unknown   \n",
       "298  China resumes construction of military base in...  Unknown   \n",
       "299  Brazil´s president: The UN was so strong enoug...  Unknown   \n",
       "\n",
       "                           date  \\\n",
       "0      May 27, 2023 at 10:37 am   \n",
       "1       May 26, 2023 at 8:11 pm   \n",
       "2       May 26, 2023 at 8:07 pm   \n",
       "3       May 26, 2023 at 7:59 pm   \n",
       "4       May 26, 2023 at 6:18 pm   \n",
       "..                          ...   \n",
       "295     May 26, 2023 at 7:59 pm   \n",
       "296     May 26, 2023 at 6:18 pm   \n",
       "297     May 12, 2023 at 2:59 pm   \n",
       "298   April 30, 2023 at 9:33 am   \n",
       "299  April 28, 2023 at 11:43 am   \n",
       "\n",
       "                                                 genre  \\\n",
       "0    Africa+Egypt+International Organisations+News+...   \n",
       "1           Africa+Europe & Russia+News+Russia+Somalia   \n",
       "2        Europe & Russia+Middle East+News+Syria+Turkey   \n",
       "3                      Africa+Lebanon+Middle East+News   \n",
       "4                          Europe & Russia+Greece+News   \n",
       "..                                                 ...   \n",
       "295                    Africa+Lebanon+Middle East+News   \n",
       "296                        Europe & Russia+Greece+News   \n",
       "297  Asia & Americas+Bahrain+Israel+Middle East+New...   \n",
       "298      Asia & Americas+China+Middle East+News+UAE+US   \n",
       "299  Africa+Asia & Americas+Brazil+Egypt+Europe & R...   \n",
       "\n",
       "                                               content  \n",
       "0    Reporters Without Borders has called on the Eg...  \n",
       "1    Somali Foreign Minister, Abshir Omar Jama, sai...  \n",
       "2    Ankara is currently working on the safe return...  \n",
       "3    Lebanon will work over the next year to addres...  \n",
       "4    Three migrants were killed and twelve others a...  \n",
       "..                                                 ...  \n",
       "295  Lebanon will work over the next year to addres...  \n",
       "296  Three migrants were killed and twelve others a...  \n",
       "297  Bahrain's educational institutions have been o...  \n",
       "298  China has resumed construction work on a milit...  \n",
       "299  Brazil's President Luiz Inácio Lula da Silva t...  \n",
       "\n",
       "[300 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4eb720ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 articles scrapped\n",
      "100 articles scrapped\n",
      "200 articles scrapped\n",
      "300 articles scrapped\n",
      "400 articles scrapped\n",
      "500 articles scrapped\n",
      "600 articles scrapped\n",
      "700 articles scrapped\n",
      "800 articles scrapped\n",
      "900 articles scrapped\n",
      "1000 articles scrapped\n",
      "1100 articles scrapped\n",
      "1200 articles scrapped\n",
      "1300 articles scrapped\n",
      "1400 articles scrapped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 articles scrapped\n",
      "1600 articles scrapped\n",
      "1700 articles scrapped\n",
      "1800 articles scrapped\n",
      "1900 articles scrapped\n",
      "2000 articles scrapped\n",
      "2100 articles scrapped\n",
      "2200 articles scrapped\n",
      "2300 articles scrapped\n",
      "2400 articles scrapped\n",
      "2500 articles scrapped\n",
      "2600 articles scrapped\n",
      "2700 articles scrapped\n",
      "2800 articles scrapped\n",
      "2900 articles scrapped\n",
      "3000 articles scrapped\n",
      "3100 articles scrapped\n",
      "3200 articles scrapped\n",
      "3300 articles scrapped\n",
      "3400 articles scrapped\n",
      "3500 articles scrapped\n",
      "3600 articles scrapped\n",
      "3700 articles scrapped\n",
      "3800 articles scrapped\n",
      "3900 articles scrapped\n",
      "4000 articles scrapped\n",
      "4100 articles scrapped\n",
      "4200 articles scrapped\n",
      "4300 articles scrapped\n",
      "headlines = 4312, writers=4312, date = 4312, genre = 4312, content=4312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hadar\\AppData\\Local\\Temp\\ipykernel_19508\\4023380378.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_mem.append(load_articles_to_df_mem(mem_urls_list,1300,5000),ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>writers</th>\n",
       "      <th>date</th>\n",
       "      <th>genre</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reporters Without Borders calls for Egypt to r...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>May 27, 2023 at 10:37 am</td>\n",
       "      <td>Africa+Egypt+International Organisations+News+...</td>\n",
       "      <td>Reporters Without Borders has called on the Eg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Russia, Somalia mull establishment of platform...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>May 26, 2023 at 8:11 pm</td>\n",
       "      <td>Africa+Europe &amp; Russia+News+Russia+Somalia</td>\n",
       "      <td>Somali Foreign Minister, Abshir Omar Jama, sai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turkiye homes in northern Syria for voluntary ...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>May 26, 2023 at 8:07 pm</td>\n",
       "      <td>Europe &amp; Russia+Middle East+News+Syria+Turkey</td>\n",
       "      <td>Ankara is currently working on the safe return...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lebanon to take steps to fix finance sector sh...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>May 26, 2023 at 7:59 pm</td>\n",
       "      <td>Africa+Lebanon+Middle East+News</td>\n",
       "      <td>Lebanon will work over the next year to addres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3 dead, 12 missing as migrant boat capsizes in...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>May 26, 2023 at 6:18 pm</td>\n",
       "      <td>Europe &amp; Russia+Greece+News</td>\n",
       "      <td>Three migrants were killed and twelve others a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>New Israel law to expel Arab students raising ...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>May 27, 2023 at 1:15 pm</td>\n",
       "      <td>Israel+Middle East+News+Palestine</td>\n",
       "      <td>The extremist Israeli government is preparing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4608</th>\n",
       "      <td>Israel settlers burn Palestine vehicles, crops...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>May 27, 2023 at 1:02 pm</td>\n",
       "      <td>Israel+Middle East+News+Palestine</td>\n",
       "      <td>Extremist Israeli settlers burnt Palestinian v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4609</th>\n",
       "      <td>Kuwait, Philippines crisis after workers' visa...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>May 27, 2023 at 12:30 pm</td>\n",
       "      <td>Asia &amp; Americas+Kuwait+Middle East+News+Philip...</td>\n",
       "      <td>A new conflict has occurred between Kuwait and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4610</th>\n",
       "      <td>Algeria ambassador to Italy sparks controversy...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>May 27, 2023 at 11:34 am</td>\n",
       "      <td>Africa+Algeria+Europe &amp; Russia+Italy+News+Tuni...</td>\n",
       "      <td>Abdelkrim Touahria has sparked controversy aft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4611</th>\n",
       "      <td>Reporters Without Borders calls for Egypt to r...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>May 27, 2023 at 10:37 am</td>\n",
       "      <td>Africa+Egypt+International Organisations+News+...</td>\n",
       "      <td>Reporters Without Borders has called on the Eg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4612 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headline  writers  \\\n",
       "0     Reporters Without Borders calls for Egypt to r...  Unknown   \n",
       "1     Russia, Somalia mull establishment of platform...  Unknown   \n",
       "2     Turkiye homes in northern Syria for voluntary ...  Unknown   \n",
       "3     Lebanon to take steps to fix finance sector sh...  Unknown   \n",
       "4     3 dead, 12 missing as migrant boat capsizes in...  Unknown   \n",
       "...                                                 ...      ...   \n",
       "4607  New Israel law to expel Arab students raising ...  Unknown   \n",
       "4608  Israel settlers burn Palestine vehicles, crops...  Unknown   \n",
       "4609  Kuwait, Philippines crisis after workers' visa...  Unknown   \n",
       "4610  Algeria ambassador to Italy sparks controversy...  Unknown   \n",
       "4611  Reporters Without Borders calls for Egypt to r...  Unknown   \n",
       "\n",
       "                          date  \\\n",
       "0     May 27, 2023 at 10:37 am   \n",
       "1      May 26, 2023 at 8:11 pm   \n",
       "2      May 26, 2023 at 8:07 pm   \n",
       "3      May 26, 2023 at 7:59 pm   \n",
       "4      May 26, 2023 at 6:18 pm   \n",
       "...                        ...   \n",
       "4607   May 27, 2023 at 1:15 pm   \n",
       "4608   May 27, 2023 at 1:02 pm   \n",
       "4609  May 27, 2023 at 12:30 pm   \n",
       "4610  May 27, 2023 at 11:34 am   \n",
       "4611  May 27, 2023 at 10:37 am   \n",
       "\n",
       "                                                  genre  \\\n",
       "0     Africa+Egypt+International Organisations+News+...   \n",
       "1            Africa+Europe & Russia+News+Russia+Somalia   \n",
       "2         Europe & Russia+Middle East+News+Syria+Turkey   \n",
       "3                       Africa+Lebanon+Middle East+News   \n",
       "4                           Europe & Russia+Greece+News   \n",
       "...                                                 ...   \n",
       "4607                  Israel+Middle East+News+Palestine   \n",
       "4608                  Israel+Middle East+News+Palestine   \n",
       "4609  Asia & Americas+Kuwait+Middle East+News+Philip...   \n",
       "4610  Africa+Algeria+Europe & Russia+Italy+News+Tuni...   \n",
       "4611  Africa+Egypt+International Organisations+News+...   \n",
       "\n",
       "                                                content  \n",
       "0     Reporters Without Borders has called on the Eg...  \n",
       "1     Somali Foreign Minister, Abshir Omar Jama, sai...  \n",
       "2     Ankara is currently working on the safe return...  \n",
       "3     Lebanon will work over the next year to addres...  \n",
       "4     Three migrants were killed and twelve others a...  \n",
       "...                                                 ...  \n",
       "4607  The extremist Israeli government is preparing ...  \n",
       "4608  Extremist Israeli settlers burnt Palestinian v...  \n",
       "4609  A new conflict has occurred between Kuwait and...  \n",
       "4610  Abdelkrim Touahria has sparked controversy aft...  \n",
       "4611  Reporters Without Borders has called on the Eg...  \n",
       "\n",
       "[4612 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mem.append(load_articles_to_df_mem(mem_urls_list,1300,5000),ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a86758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mem.to_csv('mem.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f736f230",
   "metadata": {},
   "outputs": [],
   "source": [
    "#end of scrapping MiddleEast Monitor website\n",
    "#---------------------------------------------------\n",
    "#start of scrapping Fox News website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d66a0a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scapping articles'urls from the website\n",
    "#scrapping from multiple pages with 'show more' button\n",
    "def foxnews_url_crawler(webdriver_path,max_links):\n",
    "    driver=webdriver.Chrome(executable_path=webdriver_path)\n",
    "    soup=load_soup_object('https://www.foxnews.com/category/world/world-regions/israel')\n",
    "\n",
    "    try:\n",
    "        driver.maximize_window() #ensures that the window occupies the entire screen.\n",
    "        driver.implicitly_wait(10) #wait for up to 10 seconds for the element to appear before throwing an exception\n",
    "        driver.get(\"https://www.foxnews.com/category/world/world-regions/israel\")\n",
    "\n",
    "        urls=[]\n",
    "\n",
    "        while max_links>=0:\n",
    "            if max_links%100==0: \n",
    "                print(f'{max_links} urls until finish')\n",
    "            articles=soup('article',attrs={\"class\":\"article\"})\n",
    "\n",
    "            for art in articles:\n",
    "                a=art.find('h4',attrs={\"class\":\"title\"}).find('a')\n",
    "                try:\n",
    "                    if 'href' in a.attrs:\n",
    "                        url=a.get('href')\n",
    "                        urls.append(url)\n",
    "                        max_links-=1\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            showmore=driver.find_element(\"css selector\", \"div.button.load-more.js-load-more > a\")\n",
    "\n",
    "            if showmore.is_displayed():\n",
    "                driver.execute_script(\"arguments[0].click();\", showmore)\n",
    "                time.sleep(5)\n",
    "            else:\n",
    "                print(\"no more articles to load\")\n",
    "                break\n",
    "\n",
    "    except StaleElementReferenceException:\n",
    "        pass\n",
    "    except NoSuchElementException:\n",
    "        print(\"Element not found. No more articles to load.\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "655d354b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hadar\\AppData\\Local\\Temp\\ipykernel_19508\\3621044219.py:4: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(executable_path=webdriver_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 urls until finish\n",
      "9900 urls until finish\n",
      "9800 urls until finish\n",
      "9700 urls until finish\n",
      "9600 urls until finish\n",
      "9500 urls until finish\n",
      "9400 urls until finish\n",
      "9300 urls until finish\n",
      "9200 urls until finish\n",
      "9100 urls until finish\n",
      "9000 urls until finish\n",
      "8900 urls until finish\n",
      "8800 urls until finish\n",
      "8700 urls until finish\n",
      "8600 urls until finish\n",
      "8500 urls until finish\n",
      "8400 urls until finish\n",
      "8300 urls until finish\n",
      "8200 urls until finish\n",
      "8100 urls until finish\n",
      "8000 urls until finish\n",
      "7900 urls until finish\n",
      "7800 urls until finish\n",
      "7700 urls until finish\n",
      "7600 urls until finish\n",
      "7500 urls until finish\n",
      "7400 urls until finish\n",
      "7300 urls until finish\n",
      "7200 urls until finish\n",
      "7100 urls until finish\n",
      "7000 urls until finish\n",
      "6900 urls until finish\n",
      "6800 urls until finish\n",
      "6700 urls until finish\n",
      "6600 urls until finish\n",
      "6500 urls until finish\n",
      "6400 urls until finish\n",
      "6300 urls until finish\n",
      "6200 urls until finish\n",
      "6100 urls until finish\n",
      "6000 urls until finish\n",
      "5900 urls until finish\n",
      "5800 urls until finish\n",
      "5700 urls until finish\n",
      "5600 urls until finish\n",
      "5500 urls until finish\n",
      "5400 urls until finish\n",
      "5300 urls until finish\n",
      "5200 urls until finish\n",
      "5100 urls until finish\n",
      "5000 urls until finish\n",
      "4900 urls until finish\n",
      "4800 urls until finish\n",
      "4700 urls until finish\n",
      "4600 urls until finish\n",
      "4500 urls until finish\n",
      "4400 urls until finish\n",
      "4300 urls until finish\n",
      "4200 urls until finish\n",
      "4100 urls until finish\n",
      "4000 urls until finish\n",
      "3900 urls until finish\n",
      "Element not found. No more articles to load.\n"
     ]
    }
   ],
   "source": [
    "fox_url_list=foxnews_url_crawler(webdriver_path,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c5e1ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_list_to_file('foxnews_urls.txt',fox_url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "72e69ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crawl through all articles from Fox News we've collected\n",
    "def load_articles_to_df_foxnews(urls_list):\n",
    "    headline=[]\n",
    "    writers=[]\n",
    "    date=[]\n",
    "    genre=[]\n",
    "    content=[]\n",
    "    i=0\n",
    "    \n",
    "    for url in urls_list:\n",
    "        soup=load_soup_object(r\"https://www.foxnews.com/\"+url)\n",
    "        headline.append(soup.find(\"h1\",attrs={\"class\":\"headline\"}).get_text().strip())\n",
    "        writers.append(soup.find(\"div\",attrs={\"class\":\"author-byline\"}).find(\"a\").get_text().strip())\n",
    "        date.append(soup.find(\"time\").get_text().strip())\n",
    "        genre.append(soup.find(\"div\",attrs={\"class\":\"eyebrow\"}).find(\"a\").get_text().strip())\n",
    "        content.append(\" \".join(item.get_text().strip() for item in soup.find(\"div\",attrs={\"class\":\"article-body\"}).find_all(\"p\"))) \n",
    "        i+=1\n",
    "        if(i%100==0):\n",
    "            print(f'{i} articles scrapped')\n",
    "\n",
    "    df=pd.DataFrame({\"headline\":headline,\"writers\":writers,\"date\":date,\"genre\":genre,\"content\":content})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ece1fd2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 articles scrapped\n",
      "200 articles scrapped\n",
      "300 articles scrapped\n",
      "400 articles scrapped\n",
      "500 articles scrapped\n",
      "600 articles scrapped\n",
      "700 articles scrapped\n",
      "800 articles scrapped\n",
      "900 articles scrapped\n",
      "1000 articles scrapped\n",
      "1100 articles scrapped\n",
      "1200 articles scrapped\n",
      "1300 articles scrapped\n",
      "1400 articles scrapped\n",
      "1500 articles scrapped\n",
      "1600 articles scrapped\n",
      "1700 articles scrapped\n",
      "1800 articles scrapped\n",
      "1900 articles scrapped\n",
      "2000 articles scrapped\n",
      "2100 articles scrapped\n",
      "2200 articles scrapped\n",
      "2300 articles scrapped\n",
      "2400 articles scrapped\n",
      "2500 articles scrapped\n",
      "2600 articles scrapped\n",
      "2700 articles scrapped\n",
      "2800 articles scrapped\n",
      "2900 articles scrapped\n",
      "3000 articles scrapped\n",
      "3100 articles scrapped\n",
      "3200 articles scrapped\n",
      "3300 articles scrapped\n",
      "3400 articles scrapped\n",
      "3500 articles scrapped\n",
      "3600 articles scrapped\n",
      "3700 articles scrapped\n",
      "3800 articles scrapped\n",
      "3900 articles scrapped\n",
      "4000 articles scrapped\n",
      "4100 articles scrapped\n",
      "4200 articles scrapped\n",
      "4300 articles scrapped\n",
      "4400 articles scrapped\n",
      "4500 articles scrapped\n",
      "4600 articles scrapped\n",
      "4700 articles scrapped\n",
      "4800 articles scrapped\n",
      "4900 articles scrapped\n",
      "5000 articles scrapped\n",
      "5100 articles scrapped\n",
      "5200 articles scrapped\n",
      "5300 articles scrapped\n",
      "5400 articles scrapped\n",
      "5500 articles scrapped\n",
      "5600 articles scrapped\n",
      "5700 articles scrapped\n",
      "5800 articles scrapped\n",
      "5900 articles scrapped\n",
      "6000 articles scrapped\n",
      "6100 articles scrapped\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>writers</th>\n",
       "      <th>date</th>\n",
       "      <th>genre</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jewish groups, allies demand CUNY Law lose fun...</td>\n",
       "      <td>Yael Halon</td>\n",
       "      <td>May 30, 2023 5:00am EDT</td>\n",
       "      <td>Media</td>\n",
       "      <td>Filmmaker Steven Spielberg warned against anti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Massive sea urchin die-off in Israeli gulf thr...</td>\n",
       "      <td>Associated Press</td>\n",
       "      <td>May 27, 2023 10:00am EDT</td>\n",
       "      <td>Israel</td>\n",
       "      <td>Sea otters use rocks as tools to crack tough s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Backlash against Roger Waters for antisemitism...</td>\n",
       "      <td>Lindsay Kornick</td>\n",
       "      <td>May 26, 2023 11:23am EDT</td>\n",
       "      <td>Media</td>\n",
       "      <td>Pink Floyd rocker Roger Waters tells Richard B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iran regime close to getting nuclear bomb, but...</td>\n",
       "      <td>Benjamin Weinthal</td>\n",
       "      <td>May 26, 2023 2:00am EDT</td>\n",
       "      <td>Iran</td>\n",
       "      <td>Fox News' Jennifer Griffin reports from the Pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>White House unveils first-ever national strate...</td>\n",
       "      <td>Aaron Kliegman</td>\n",
       "      <td>May 25, 2023 5:17pm EDT</td>\n",
       "      <td>Antisemitism</td>\n",
       "      <td>Filmmaker Steven Spielberg warned against anti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6105</th>\n",
       "      <td>Israel's defense chief warns Tehran against fu...</td>\n",
       "      <td>Caitlin McFall</td>\n",
       "      <td>May 23, 2023 10:53am EDT</td>\n",
       "      <td>Iran</td>\n",
       "      <td>U.S. Central Command and the IDF took part in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6106</th>\n",
       "      <td>CNN’s Christine Amanpour apologizes after wron...</td>\n",
       "      <td>Jeffrey Clark</td>\n",
       "      <td>May 23, 2023 10:42am EDT</td>\n",
       "      <td>Media</td>\n",
       "      <td>CNN chief international correspondent Christia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6107</th>\n",
       "      <td>Israel more than doubled strikes on Iranian ta...</td>\n",
       "      <td>Associated Press</td>\n",
       "      <td>May 22, 2023 8:07pm EDT</td>\n",
       "      <td>Israel</td>\n",
       "      <td>Fox News Flash top headlines are here. Check o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>Iran building nuclear facility deep enough tha...</td>\n",
       "      <td>Michael Lee</td>\n",
       "      <td>May 22, 2023 1:31pm EDT</td>\n",
       "      <td>Iran</td>\n",
       "      <td>Exiled Crown Prince of Iran Reza Pahlavi joine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6109</th>\n",
       "      <td>In the footsteps of Jesus: 2,000-year-old trad...</td>\n",
       "      <td>Caitlin McFall</td>\n",
       "      <td>May 21, 2023 6:00am EDT</td>\n",
       "      <td>Digging History</td>\n",
       "      <td>Israel Antiquities Authority discovers 2,000-y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6110 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headline            writers  \\\n",
       "0     Jewish groups, allies demand CUNY Law lose fun...         Yael Halon   \n",
       "1     Massive sea urchin die-off in Israeli gulf thr...   Associated Press   \n",
       "2     Backlash against Roger Waters for antisemitism...    Lindsay Kornick   \n",
       "3     Iran regime close to getting nuclear bomb, but...  Benjamin Weinthal   \n",
       "4     White House unveils first-ever national strate...     Aaron Kliegman   \n",
       "...                                                 ...                ...   \n",
       "6105  Israel's defense chief warns Tehran against fu...     Caitlin McFall   \n",
       "6106  CNN’s Christine Amanpour apologizes after wron...      Jeffrey Clark   \n",
       "6107  Israel more than doubled strikes on Iranian ta...   Associated Press   \n",
       "6108  Iran building nuclear facility deep enough tha...        Michael Lee   \n",
       "6109  In the footsteps of Jesus: 2,000-year-old trad...     Caitlin McFall   \n",
       "\n",
       "                          date            genre  \\\n",
       "0      May 30, 2023 5:00am EDT            Media   \n",
       "1     May 27, 2023 10:00am EDT           Israel   \n",
       "2     May 26, 2023 11:23am EDT            Media   \n",
       "3      May 26, 2023 2:00am EDT             Iran   \n",
       "4      May 25, 2023 5:17pm EDT     Antisemitism   \n",
       "...                        ...              ...   \n",
       "6105  May 23, 2023 10:53am EDT             Iran   \n",
       "6106  May 23, 2023 10:42am EDT            Media   \n",
       "6107   May 22, 2023 8:07pm EDT           Israel   \n",
       "6108   May 22, 2023 1:31pm EDT             Iran   \n",
       "6109   May 21, 2023 6:00am EDT  Digging History   \n",
       "\n",
       "                                                content  \n",
       "0     Filmmaker Steven Spielberg warned against anti...  \n",
       "1     Sea otters use rocks as tools to crack tough s...  \n",
       "2     Pink Floyd rocker Roger Waters tells Richard B...  \n",
       "3     Fox News' Jennifer Griffin reports from the Pe...  \n",
       "4     Filmmaker Steven Spielberg warned against anti...  \n",
       "...                                                 ...  \n",
       "6105  U.S. Central Command and the IDF took part in ...  \n",
       "6106  CNN chief international correspondent Christia...  \n",
       "6107  Fox News Flash top headlines are here. Check o...  \n",
       "6108  Exiled Crown Prince of Iran Reza Pahlavi joine...  \n",
       "6109  Israel Antiquities Authority discovers 2,000-y...  \n",
       "\n",
       "[6110 rows x 5 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fox=load_articles_to_df_foxnews(fox_url_list)\n",
    "df_fox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "37e0716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fox.to_csv('fox.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c048be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping frpm nbc News website all articles' urls\n",
    "def scrapping_all_urls_from_nbc_news(url_1)\n",
    "    urls = []\n",
    "    specific_urls = [\"politics\", \"us-news\", \"world\", \"business\", \"tech-media\", \"health\", \"culture-matters\"]\n",
    "\n",
    "    for url_part in specific_urls:\n",
    "        base_url = url_1 + url_part\n",
    "\n",
    "        webdriver_path = r\"C:\\Users\\ofir\\Downloads\\chromedriver_win32\\chromedriver.exe\"\n",
    "        driver = webdriver.Chrome(executable_path=webdriver_path)\n",
    "        driver.maximize_window()\n",
    "        driver.implicitly_wait(10)\n",
    "        driver.get(base_url)\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                loadmore = driver.find_element(By.CSS_SELECTOR, 'button.animated-ghost-button')\n",
    "                if not loadmore.is_displayed():\n",
    "                    break\n",
    "                loadmore.click()\n",
    "                time.sleep(10)\n",
    "                soup = load_soup_object_with_file_content(driver.page_source)\n",
    "                articles = soup.find_all('div', attrs={\"class\": \"wide-tease-item__info-wrapper flex-grow-1-m\"})\n",
    "                for article in articles:\n",
    "                    try:\n",
    "                        a_elements = article.find_all('a')[-1]\n",
    "                        if 'href' in a_elements.attrs:\n",
    "                            url = a_elements.get('href')\n",
    "                            if url not in urls:  \n",
    "                                urls.append(url)\n",
    "                    except:\n",
    "                        print(\"exception in articles loop\")\n",
    "\n",
    "        except StaleElementReferenceException:\n",
    "            pass\n",
    "        except  NoSuchElementException:\n",
    "            pass\n",
    "\n",
    "    driver.quit()\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85436361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crawler for nbc News website\n",
    "def load_articles_to_df_nbcnews(urls_list):\n",
    "    headline=[]\n",
    "    writers=[]\n",
    "    date=[]\n",
    "    genre=[]\n",
    "    content=[]\n",
    "    i=0\n",
    "    for url in urls_list:\n",
    "        soup = load_soup_object_with_file_name(url)\n",
    "        try:\n",
    "            headline.append(soup.find(\"div\",attrs={\"class\":\"article-hero-headline layout-grid-item grid-col-10-l\"}).find(\"h1\").get_text().strip())\n",
    "            writers.append(soup.find(\"span\",attrs={\"class\":\"byline-name\"}).get_text().strip())\n",
    "            date.append(soup.find(\"time\",attrs={\"class\":\"relative z-1\"}).get_text().strip())   \n",
    "            genre.append(soup.find(\"div\",attrs={\"class\":\"unibrow articleTitleSection article-hero__tax-term\"}).get_text().strip())    \n",
    "            content_element = soup.find(\"div\", class_=\"article-body__content\")\n",
    "            if content_element:\n",
    "                paragraphs = content_element.find_all(\"p\")\n",
    "                content1 = \"\"\n",
    "                for paragraph in paragraphs:\n",
    "                # Break the loop if a specific condition is met, such as finding a specific HTML line or tag\n",
    "                    if paragraph.find(\"top_share_widget\"):\n",
    "                        break\n",
    "                    content1 += paragraph.get_text().strip() + \" \"  \n",
    "                content.append(content1)\n",
    "            else:\n",
    "                content.append(\"None\")\n",
    "            i+=1\n",
    "            if(i%100==0):\n",
    "                print(f'{i} articles scrapped')\n",
    "        except:\n",
    "            print(\"error in link: \" + url)\n",
    "    df= pd.DataFrame({\"headline\":headline, \"writers\":writers,\"date\":date,\"genre\":genre,\"content\":content})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7964586",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_1 = \"https://www.nbcnews.com/\"\n",
    "urls = scrapping_all_urls_from_nbc_news(url_1)\n",
    "df1 = load_articles_to_df_nbcnews(urls)\n",
    "df1.to_csv('nbcnews.csv', index=False)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c77087",
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "#--------------------\n",
    "###crawler for Empire new - Fake news website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd549c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapping_all_urls_from_empire_news(base_url)    \n",
    "    \n",
    "    urls = []\n",
    "\n",
    "    for page in range(1,280):\n",
    "        pages_list = base_url.format(page)\n",
    "        response = requests.get(pages_list)\n",
    "        soup = BeautifulSoup(response.content,\"html.parser\")\n",
    "        articles=soup('div',attrs={\"class\":\"span6 home-post\"})\n",
    "\n",
    "        for art in articles:\n",
    "            a=art.find('a')\n",
    "            try:\n",
    "                if 'href' in a.attrs:\n",
    "                    url=a.get('href')\n",
    "                    urls.append(url)\n",
    "            except:\n",
    "                continue\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2bd0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_articles_to_df_empirenews(urls_list):\n",
    "    headline=[]\n",
    "    writers=[]\n",
    "    date=[]\n",
    "    genre=[]\n",
    "    content=[]\n",
    "    i=0\n",
    "    for url in urls_list:\n",
    "        try:\n",
    "            soup=load_soup_object_with_file_name(url)\n",
    "            headline.append(soup.find(\"h1\",attrs={\"class\":\"entry-title\"}).get_text().strip())\n",
    "            writers.append(soup.find(\"span\",attrs={\"class\":\"author vcard\"}).get_text().strip())\n",
    "            date.append(soup.find(\"time\",attrs={\"class\":\"entry-date published updated\"}).get_text().strip())   \n",
    "            genre.append(soup.find(\"span\",attrs={\"class\":\"cat-links\"}).get_text().strip())    \n",
    "            content_element = soup.find(\"div\", class_=\"entry-content\")\n",
    "            if content_element:\n",
    "                paragraphs = content_element.find_all(\"p\")\n",
    "                content1 = \"\"\n",
    "                for paragraph in paragraphs:\n",
    "                # Break the loop if a specific condition is met, such as finding a specific HTML line or tag\n",
    "                    if paragraph.find(\"top_share_widget\"):\n",
    "                        break\n",
    "                    content1 += paragraph.get_text().strip() + \" \"  \n",
    "                content.append(content1)\n",
    "            else:\n",
    "                content.append(\"None\")\n",
    "            i+=1\n",
    "            if(i%100==0):\n",
    "                print(f'{i} articles scrapped')\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    df= pd.DataFrame({\"headline\":headline,\"writers\":writers,\"date\":date,\"genre\":genre,\"content\":content})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68beff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://empirenews.net/page/{}/\"\n",
    "urls = scrapping_all_urls_from_empire_news(base_url)    \n",
    "my_df = load_articles_to_df_empirenews(urls)\n",
    "my_df.to_csv('empirenews.csv',index=False)\n",
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75106b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
